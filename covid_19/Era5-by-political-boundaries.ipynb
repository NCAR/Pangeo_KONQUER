{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsetting ERA5 to political boundaries\n",
    "==================\n",
    "\n",
    "In this notebook, we download ERA5 precipitation and temperature data and subset it to political boundaries (countries and states/provinces). We write these out to two csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "import cartopy\n",
    "import cdsapi\n",
    "import geopandas\n",
    "import hvplot.pandas  # noqa\n",
    "import regionmask\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy import crs as ccrs\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "xr.set_options(display_style='html')\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "assert regionmask.__version__ == '0.5.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the latest ERA5 data\n",
    "\n",
    "These requires authenticating with the Copernicus Climate Data Store. \n",
    "\n",
    "You'll need a file named `.cdsapirc` in your home directory with the following details:\n",
    "```\n",
    "url: https://cds.climate.copernicus.eu/api/v2\n",
    "key: XXXX:1234567-1234-1234-1234-1234567890\n",
    "```\n",
    "Be sure to replace both parts of the `XXXX` with your UID and the remainder with your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url: https://cds.climate.copernicus.eu/api/v2\n",
    "# key: XXXX:1234567-1234-1234-1234-1234567890\n",
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell will download data from the CDS, placing a new file (`download.nc`) in your working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels-monthly-means',\n",
    "    {\n",
    "        'format': 'netcdf',\n",
    "        'product_type': 'monthly_averaged_reanalysis',\n",
    "        'variable': [\n",
    "            '2m_temperature', 'total_precipitation',\n",
    "        ],\n",
    "        'year': [\n",
    "            '2019', '2020',\n",
    "        ],\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'time': '00:00',\n",
    "    },\n",
    "    'download.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can open the ERA5 dataset. This dataset comes with two experiements, we'll merge them since they don't overlap in their forecast time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the dataset\n",
    "ds = xr.open_dataset('download.nc')\n",
    "# merge the experiments\n",
    "ds = ds.bfill('expver').isel(expver=0)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the last timestep\n",
    "ds['t2m'].isel(time=-1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a timeseries at one location\n",
    "ds['t2m'].sel(longitude=114.3055, latitude=30.5928, method='nearest').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting ERA5 by political boundaries\n",
    "\n",
    "The ERA5 data we plotted above is still in its gridded format. If we want to subset this data by political boundary, we need to bring in a shapefile. Below we define two functions that will help us do this subsetting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdf(resolution='50m', category='cultural', name='admin_0_countries'):\n",
    "    '''return a geopandas.GeoDataFrame of boundaries\n",
    "    \n",
    "    More info: https://www.naturalearthdata.com/downloads/\n",
    "    '''\n",
    "    fname = cartopy.io.shapereader.natural_earth(\n",
    "      resolution=resolution,\n",
    "      category=category,\n",
    "      name=name)    \n",
    "\n",
    "    gdf = geopandas.GeoDataFrame.from_file(fname)   \n",
    "    gdf['cent_lon'] = gdf.geometry.centroid.x\n",
    "    gdf['cent_lon'].values[gdf['cent_lon'].values < 0] += 360.\n",
    "    gdf['cent_lat'] = gdf.geometry.centroid.y\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "\n",
    "def subset_by_gdf(ds, gdf, var='t2m'):\n",
    "    '''Subset a dataset (ds) using the shapes defined in a GeoDataFrame (gdf)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    final_df : geopandas.GeoDataFrame\n",
    "    \n",
    "    '''\n",
    "    # create masks\n",
    "    print('Creating masks...')\n",
    "    shapes = regionmask.Regions(gdf.geometry)\n",
    "    mask = shapes.mask(ds, lon_name='longitude', lat_name='latitude', wrap_lon=True)\n",
    "\n",
    "    print('looping over shapes...')\n",
    "    # loop over shapes\n",
    "    df = pd.DataFrame(index=ds.indexes['time'])\n",
    "    for val, row in tqdm(gdf.iterrows()):\n",
    "        if not (mask == val).values.any():\n",
    "            data = ds[var].sel(latitude=row['cent_lat'], longitude=row['cent_lon'], method='nearest', tolerance=1)\n",
    "        else:\n",
    "            data = ds[var].where(mask == val).mean(('latitude', 'longitude'))\n",
    "        df[val] = data.to_series()\n",
    "        if var == 't2m':\n",
    "            df[val] -= 273.15\n",
    "    \n",
    "    # setup final dataframe\n",
    "    df.index = df.index.to_period()\n",
    "    df = df['2019-11-01':].transpose()\n",
    "    \n",
    "    final_df = gdf.merge(df, right_index=True, left_index=True)\n",
    "    final_df.crs = ccrs.PlateCarree().proj4_init\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_gdf(resolution='110m')\n",
    "countries = subset_by_gdf(ds, gdf, var='t2m')\n",
    "\n",
    "display(countries.head())\n",
    "countries.hvplot(c='2019-12', cmap='viridis', hover_cols=['ADMIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = get_gdf(resolution='10m', name='admin_1_states_provinces')\n",
    "states = subset_by_gdf(ds, gdf, var='t2m')\n",
    "\n",
    "display(states.head())\n",
    "states.hvplot(c='2019-12', cmap='viridis')  # TODO fix the hover tools here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "pd.DataFrame(countries).drop(columns=['geometry']).to_csv('era5_ne_countries.csv', encoding='utf-8')\n",
    "pd.DataFrame(states).drop(columns=['geometry']).to_csv('era5_ne_states.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
