{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from contextlib import closing\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in era5 files\n",
    "states_file = '../era5_ne_states.csv'\n",
    "era5_states = pd.read_csv(states_file).to_xarray()\n",
    "\n",
    "countries_file = '../era5_ne_countries.csv'\n",
    "era5_countries = pd.read_csv(countries_file).to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_era5_index(lat, lon, era5):\n",
    "    '''\n",
    "    Returns the era5 index corresponding with the closet lat-lon coordinate\n",
    "\n",
    "            Parameters:\n",
    "                    lat (float): latitude value from covid19 data\n",
    "                    lon (float): longitude value from covid19 data\n",
    "                    era5 (xr.Dataset): era5 dataset for either states or countries. \n",
    "                        Accepts: `era5_states` or `era5_countries`\n",
    "\n",
    "            Returns:\n",
    "                    index (int): index from era5 dataset that maps to a state or country\n",
    "    '''\n",
    "    era5_index = era5.index.values\n",
    "    era5_lat = era5.cent_lat.values\n",
    "    era5_lon = era5.cent_lon.values\n",
    "\n",
    "    dist = [(lat - era5_lat[i])**2 + (lon - era5_lon[i])**2 for i in era5_index]\n",
    "    index = dist.index(min(dist))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read COVID19 data from url and create xr.Dataset\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "\n",
    "with closing(requests.get(url, stream=True)) as r:\n",
    "    f = (line.decode('utf-8') for line in r.iter_lines())\n",
    "    reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    header = next(reader)\n",
    "    time = pd.date_range(start=header[4], end=header[-1])\n",
    "    \n",
    "    ds_dict = {} \n",
    "    for line in reader:\n",
    "        state = line[0]\n",
    "        country = line[1]\n",
    "        lat = float(line[2])\n",
    "        lon = float(line[3])\n",
    "        cases = [int(i) for i in line[4:]]\n",
    "        \n",
    "        if state:\n",
    "            region_name = (state +'_' + country).replace(' ', '_').lower()\n",
    "        else:\n",
    "            region_name = country.replace(' ', '_').replace(',', '').lower()     \n",
    "        \n",
    "        states_index = find_era5_index(lat, lon, era5_states)\n",
    "        countries_index = find_era5_index(lat, lon, era5_countries)\n",
    "        \n",
    "        da = xr.DataArray(cases, coords = [time], dims = ['time'], name = region_name)\n",
    "        da.attrs['lat'] = lat\n",
    "        da.attrs['lon'] = lon\n",
    "        da.attrs['state'] = era5_states.name_en[states_index].values\n",
    "        da.attrs['state_index'] = states_index\n",
    "        da.attrs['country'] = era5_countries.NAME_EN[countries_index].values\n",
    "        da.attrs['country_index'] = countries_index\n",
    "        \n",
    "        ds_dict[region_name] = da.to_dict()\n",
    "\n",
    "ds = xr.Dataset.from_dict(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'korea_south' (time: 65)>\n",
       "array([   1,    1,    2,    2,    3,    4,    4,    4,    4,   11,   12,   15,\n",
       "         15,   16,   19,   23,   24,   24,   25,   27,   28,   28,   28,   28,\n",
       "         28,   29,   30,   31,   31,  104,  204,  433,  602,  833,  977, 1261,\n",
       "       1766, 2337, 3150, 3736, 4335, 5186, 5621, 6088, 6593, 7041, 7314, 7478,\n",
       "       7513, 7755, 7869, 7979, 8086, 8162, 8236, 8320, 8413, 8565, 8652, 8799,\n",
       "       8961, 8961, 9037, 9137, 9241])\n",
       "Dimensions without coordinates: time\n",
       "Attributes:\n",
       "    lat:            36.0\n",
       "    lon:            128.0\n",
       "    state:          Daegu\n",
       "    state_index:    4141\n",
       "    country:        South Korea\n",
       "    country_index:  96"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['korea_south']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_duplicated_indices(ds, region_level='states'):\n",
    "    '''\n",
    "    Checks if more than one region in the xr.Dataset correspond to the same state or country index \n",
    "    and adds COVID19 cases together for those regions.\n",
    "\n",
    "            Parameters:\n",
    "                    ds (xr.Dataset): COVID19 data\n",
    "                    region_level (str): specification of combining regions based on state or country index \n",
    "                        Accepts: `states` or `countries`\n",
    "\n",
    "            Returns:\n",
    "                    ds_era5_regions (xr.Dataset): COVID19 data mapped to era\n",
    "    '''\n",
    "    ds = ds.copy()\n",
    "    era5_regions_dict = {}\n",
    "\n",
    "    index_set = set()\n",
    "    for region in ds:\n",
    "        \n",
    "        if region_level == 'countries':\n",
    "            name = ds[region].attrs['country']\n",
    "            index = ds[region].attrs['country_index']\n",
    "            \n",
    "            del ds[region].attrs['state']\n",
    "            del ds[region].attrs['state_index']\n",
    "            \n",
    "        elif region_level == 'states':\n",
    "            name = ds[region].attrs['state']\n",
    "            index = ds[region].attrs['state_index']\n",
    "        \n",
    "        region_dict = ds[region].to_dict()\n",
    "        if index not in index_set:\n",
    "            index_set.add(index)\n",
    "            era5_regions_dict[name] = region_dict\n",
    "        else:\n",
    "            era5_regions_dict[name]['data'] = np.add(era5_regions_dict[name]['data'], region_dict['data'])\n",
    "            \n",
    "    ds_era5_regions = xr.Dataset.from_dict(era5_regions_dict)\n",
    "    return ds_era5_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'South Korea' (time: 65)>\n",
       "array([    4,    12,    26,    47,    82,   126,   169,   233,   291,   363,\n",
       "         420,   481,   545,   599,   667,   743,   818,   879,   937,   985,\n",
       "        1030,  1068,  1107,  1144,  1164,  1183,  1197,  1203,  1206,  1281,\n",
       "        1584,  1814,  1987,  2219,  2364,  2648,  3153,  3724,  4537,  5125,\n",
       "        5724,  6575,  7010,  7477,  7982,  8430,  8703,  8867,  8902,  9146,\n",
       "        9260,  9370,  9477,  9553,  9627,  9712,  9805,  9957, 10045, 10194,\n",
       "       10361, 10362, 10441, 10544, 10652])\n",
       "Dimensions without coordinates: time\n",
       "Attributes:\n",
       "    lat:            32.9711\n",
       "    lon:            119.455\n",
       "    country:        South Korea\n",
       "    country_index:  96"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_countries = combine_duplicated_indices(ds, region_level='countries')\n",
    "ds_countries['South Korea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'Urozgan' (time: 65)>\n",
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  4,  5,  7,  7,  7, 11, 16,\n",
       "       21, 22, 22, 22, 24, 24, 40, 40, 74, 84, 94])\n",
       "Dimensions without coordinates: time\n",
       "Attributes:\n",
       "    lat:            33.0\n",
       "    lon:            65.0\n",
       "    state:          Urozgan\n",
       "    state_index:    3885\n",
       "    country:        Afghanistan\n",
       "    country_index:  103"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_states = combine_duplicated_indices(ds, region_level='states')\n",
    "ds_states['Urozgan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
